import csv
import re
from transformers import AutoTokenizer

# Initialize the BERT tokenizer
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Function to extract rate
def extract_rate(text):
    rate_pattern = r'\b\d{1,4}(?:\.\d{1,4})?\b'
    rates = re.findall(rate_pattern, text)
    rates = [float(rate) for rate in rates if 100 < float(rate) < 1000]
    return rates[0] if rates else None

# Function to determine sentiment
def get_sentiment(text):
    positive_words = ['good', 'appreciate', 'deal', 'done', 'smooth']
    negative_words = ['tight', 'below', "isn't", 'comfortable']

    positive_count = sum(1 for word in positive_words if word in text.lower())
    negative_count = sum(1 for word in negative_words if word in text.lower())

    if positive_count > negative_count:
        return 'Positive'
    elif negative_count > positive_count:
        return 'Negative'
    else:
        return 'Neutral'

# Function to read chat from file
def read_chat_from_file():
    chat_lines = []
    current_speaker = ""
    current_message = ""

    # Set the file path to 'T1.txt' located in the same directory as the script
    file_path = 'T1.txt'

    with open(file_path, 'r', encoding='utf-8') as file:
        for line in file:
            line = line.strip()
            if line.startswith("**") and line.endswith(":**"):
                if current_speaker and current_message:
                    chat_lines.append((current_speaker, current_message.strip()))
                current_speaker = line.strip("**:")
                current_message = ""
            elif not line.startswith("*"):
                current_message += " " + line

        # Add the last message
        if current_speaker and current_message:
            chat_lines.append((current_speaker, current_message.strip()))

    return chat_lines

# Process the chat and create CSV content
csv_content = [['Trader', 'Tokens', 'Rate', 'Sentiment']]

# Read chat lines from local file T1.txt
chat_lines = read_chat_from_file()

for speaker, message in chat_lines:
    # Ensure tokenizer and relevant functions are defined
    if 'tokenizer' not in locals() or 'extract_rate' not in locals() or 'get_sentiment' not in locals():
        raise ValueError("Tokenizer or processing functions are not defined.")

    # Use BERT tokenizer
    bert_tokens = tokenizer.tokenize(message)

    # Extract relevant information
    rate = extract_rate(message)
    sentiment = get_sentiment(message)

    # Append processed data to csv_content
    csv_content.append([speaker, bert_tokens, rate, sentiment])

# Now, csv_content contains the results and can be saved or used for further processing
    csv_content.append([
        speaker,
        ' '.join(bert_tokens),  # Join BERT tokens into a string
        rate if rate else '',
        sentiment
    ])

# Display CSV content
for row in csv_content:
    print(','.join(map(str, row)))
