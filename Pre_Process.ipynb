{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load the FinBERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n",
    "model = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone', num_labels=3)\n",
    "\n",
    "def preprocess_chat_transcriptions(input_dir, output_file):\n",
    "    data = defaultdict(list)\n",
    "\n",
    "    # Loop through all text files in the input directory\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith('.txt'):\n",
    "            with open(os.path.join(input_dir, filename), 'r') as file:\n",
    "                text = file.read().strip()\n",
    "\n",
    "            # Tokenize the text and prepare input for FinBERT\n",
    "            inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "\n",
    "            # Get sentiment predictions\n",
    "            predictions = outputs.logits.argmax(dim=1).item()  # 0: negative, 1: neutral, 2: positive\n",
    "\n",
    "            # Append sentiment based on FinBERT predictions\n",
    "            sentiment = ['negative', 'neutral', 'positive'][predictions]\n",
    "            data['sentiment'].append(sentiment)\n",
    "\n",
    "            # You can tokenize the text for other usages if needed\n",
    "            tokens = tokenizer.tokenize(text)\n",
    "            data['tokens'].append(tokens)\n",
    "\n",
    "            # Parse the 'rates' column from the filename\n",
    "            rate = filename.split('_')[-1].replace('.txt', '')\n",
    "            if 'k' in rate:\n",
    "                data['rates'].append(float(rate.replace('k', '')) * 1000)\n",
    "            else:\n",
    "                if rate.isnumeric():\n",
    "                    data['rates'].append(float(rate))\n",
    "                else:\n",
    "                    data['rates'].append(0)  # Default value for non-numeric rates\n",
    "\n",
    "    # Create a DataFrame and fill null values\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "# Example usage\n",
    "input_dir = \"D:\\\\ABX\\\\Chat_Scripts\"\n",
    "output_file = \"D:\\\\ABX\\\\Datasets\\\\processed_chat_data.csv\"  # Ensure this is a valid file name\n",
    "preprocess_chat_transcriptions(input_dir, output_file)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
